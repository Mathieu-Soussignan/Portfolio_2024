---
title: StoryMaker â€“ GÃ©nÃ©rateur d'Histoires IA
publishDate: 2024-04-12 00:00:00
img: /assets/storymaker-thumbnail.jpg
img_alt: Capture de l'application StoryMaker en Streamlit
description: |
  Application IA de gÃ©nÃ©ration dâ€™histoires personnalisÃ©es en franÃ§ais. Interface en Streamlit, backend en FastAPI et gÃ©nÃ©ration via le modÃ¨le LLaMA avec Ollama.
tags:
  - IA
  - FastAPI
  - Ollama
  - NLP
---

## Ã€ propos du projet

**StoryMaker** est une application web conÃ§ue pour permettre la gÃ©nÃ©ration d'histoires captivantes en franÃ§ais grÃ¢ce Ã  l'intelligence artificielle. Le projet vise Ã  rendre la crÃ©ation de rÃ©cits accessible et personnalisable, aussi bien pour les amateurs que pour les auteurs Ã  la recherche dâ€™inspiration.

DÃ©veloppÃ©e dans le cadre dâ€™un projet IA avec mon binÃ´me **Yamine Aissani**, cette application met l'accent sur l'interaction homme-machine Ã  travers une interface intuitive et un backend robuste communiquant avec le modÃ¨le **LLaMA** via **Ollama**.

### FonctionnalitÃ©s principales

- ğŸ­ **Choix du genre** : Aventure, Fantastique, ComÃ©die, Horreur, Science-fiction.
- ğŸ“ **Longueur personnalisable** : de 100 Ã  400 mots.
- ğŸ“š **Prompts prÃ©dÃ©finis** pour inspirer lâ€™utilisateur.
- ğŸ“Š **Statistiques** : mots, caractÃ¨res, mots-clÃ©s frÃ©quents.
- ğŸ’¾ **Historique** : sauvegarde et accÃ¨s aux anciennes histoires.
- ğŸ“¥ **TÃ©lÃ©chargement** des histoires en `.pdf` ou `.txt`.
- âš™ï¸ **Backend FastAPI** connectÃ© Ã  **Ollama** pour la gÃ©nÃ©ration textuelle.
- ğŸ“ˆ **Visualisation de donnÃ©es** avec `matplotlib`.
- ğŸ“ƒ **GÃ©nÃ©ration de PDF** stylisÃ©s via `fpdf`.

### Technologies utilisÃ©es

- **Frontend** : Streamlit
- **Backend** : FastAPI
- **ModÃ¨le IA** : LLaMA via Ollama (serveur local)
- **Librairies Python** : Matplotlib, FPDF, Pillow
- **DÃ©ploiement local** : Ngrok, possibilitÃ© dâ€™hÃ©bergement cloud

### Architecture technique

```plaintext
Streamlit (interface utilisateur)
        â†“
    FastAPI (API REST)
        â†“
   Ollama (serveur IA avec LLaMA)
```

### LeÃ§ons tirÃ©es

- Mise en place dâ€™une communication stable entre Frontend (Streamlit) et Backend (FastAPI).
- Exploitation dâ€™un modÃ¨le IA local avec Ollama.
- Gestion des formats dâ€™export (.pdf, .txt) et statistiques NLP simples.

### Voir le projet

- [Code source GitHub](https://github.com/Mathieu-Soussignan/Text_generator)